<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/infinite-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/infinite-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"awayx.online","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"livere","storage":true,"lazyload":false,"nav":null,"activeClass":"livere"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="JSTSP 2020 MC2 论文  Abstract如今，360°视频&#x2F;图像越来越受欢迎并引起了广泛关注。由于360°视频&#x2F;图像的球面视角范围涉及大量数据，这对解决存储、传输等瓶颈的360°视频&#x2F;图像处理提出了挑战。因此，近年来涌现出了大量关于360°视频&#x2F;图像处理的研究工作。本文从感知、评估和压缩三个方面回顾了360°视频&#x2F;图像处理的最新研究进展。首先，本文回顾了360°视频&#x2F;图像的相关数据">
<meta property="og:type" content="article">
<meta property="og:title" content="State-of-the-Art in 360° Video_Image Processing - Perception, Assessment and Compression">
<meta property="og:url" content="http://awayx.online/2024/08/19/State-of-the-Art%20in%20360%C2%B0%20Video_Image%20Processing%20-%20Perception,%20Assessment%20and%20Compression/index.html">
<meta property="og:site_name" content="AwaySpace">
<meta property="og:description" content="JSTSP 2020 MC2 论文  Abstract如今，360°视频&#x2F;图像越来越受欢迎并引起了广泛关注。由于360°视频&#x2F;图像的球面视角范围涉及大量数据，这对解决存储、传输等瓶颈的360°视频&#x2F;图像处理提出了挑战。因此，近年来涌现出了大量关于360°视频&#x2F;图像处理的研究工作。本文从感知、评估和压缩三个方面回顾了360°视频&#x2F;图像处理的最新研究进展。首先，本文回顾了360°视频&#x2F;图像的相关数据">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://vip.helloimg.com/i/2024/08/19/66c34586e1f2f.png">
<meta property="og:image" content="https://vip.helloimg.com/i/2024/08/19/66c33c951d101.png">
<meta property="og:image" content="https://vip.helloimg.com/i/2024/08/19/66c3458ed2512.png">
<meta property="og:image" content="https://vip.helloimg.com/i/2024/08/19/66c3458cb176e.png">
<meta property="og:image" content="https://vip.helloimg.com/i/2024/08/19/66c3458910bd1.png">
<meta property="article:published_time" content="2024-08-19T13:20:53.000Z">
<meta property="article:modified_time" content="2024-08-19T13:26:33.134Z">
<meta property="article:author" content="AwayX">
<meta property="article:tag" content="论文笔记">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://vip.helloimg.com/i/2024/08/19/66c34586e1f2f.png">

<link rel="canonical" href="http://awayx.online/2024/08/19/State-of-the-Art%20in%20360%C2%B0%20Video_Image%20Processing%20-%20Perception,%20Assessment%20and%20Compression/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>State-of-the-Art in 360° Video_Image Processing - Perception, Assessment and Compression | AwaySpace</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">AwaySpace</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">8</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">44</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">35</span></a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://awayx.online/2024/08/19/State-of-the-Art%20in%20360%C2%B0%20Video_Image%20Processing%20-%20Perception,%20Assessment%20and%20Compression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/TheRightToCry.jpg">
      <meta itemprop="name" content="AwayX">
      <meta itemprop="description" content="嘿嘿">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AwaySpace">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          State-of-the-Art in 360° Video_Image Processing - Perception, Assessment and Compression
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2024-08-19 21:20:53 / 修改时间：21:26:33" itemprop="dateCreated datePublished" datetime="2024-08-19T21:20:53+08:00">2024-08-19</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Computer-Vision/" itemprop="url" rel="index"><span itemprop="name">Computer Vision</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Computer-Vision/%E7%BB%BC%E8%BF%B0/" itemprop="url" rel="index"><span itemprop="name">综述</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Computer-Vision/%E7%BB%BC%E8%BF%B0/ODI/" itemprop="url" rel="index"><span itemprop="name">ODI</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Computer-Vision/%E7%BB%BC%E8%BF%B0/ODI/2020/" itemprop="url" rel="index"><span itemprop="name">2020</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Computer-Vision/%E7%BB%BC%E8%BF%B0/ODV/" itemprop="url" rel="index"><span itemprop="name">ODV</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Computer-Vision/%E7%BB%BC%E8%BF%B0/ODV/2020/" itemprop="url" rel="index"><span itemprop="name">2020</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <blockquote>
<p><strong>JSTSP 2020</strong></p>
<p>MC2 论文</p>
</blockquote>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>如今，360°视频/图像越来越受欢迎并引起了广泛关注。由于360°视频/图像的球面视角范围涉及大量数据，这对解决存储、传输等瓶颈的360°视频/图像处理提出了挑战。因此，近年来涌现出了大量关于360°视频/图像处理的研究工作。本文从感知、评估和压缩三个方面回顾了360°视频/图像处理的最新研究进展。首先，本文回顾了360°视频/图像的相关数据集和视觉注意力建模方法。其次，我们综述了360°视频/图像在主观和客观视觉质量评估（VQA）方面的相关研究。第三，我们概述了360°视频/图像的压缩方法，这些方法或是利用了球面特性，或是结合了视觉注意力模型。最后，我们总结了本文的综述内容，并展望了360°视频/图像处理领域的未来研究趋势。</p>
<span id="more"></span>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>360°视频/图像，也称为全景、球形或全向视频/图像，是一种提供沉浸式体验的新型多媒体。360°视频/图像的内容位于覆盖整个360×180°视角范围的球面上。换句话说，360°视频/图像无缝地包围了观众，占据了观众的整个视野，这与仅覆盖有限平面的传统二维（2D）视频/图像不同。近年来，虚拟现实（VR）技术迅速发展。作为VR内容的重要类型，360°视频/图像已大量涌入我们的日常生活并引起了广泛关注。随着<strong>商业头戴显示器</strong>（<strong>HMD</strong>）的普及，观众可以通过<strong>头部运动</strong>（<strong>HM</strong>）自由地将视口聚焦在所需内容上，就像人在现实世界中一样。通过这种方式，技术上实现了沉浸式甚至是交互式体验。</p>
<p>同时，360°视频/图像处理面临新的挑战。为了以高保真度覆盖整个360×180°的视角范围，360°视频/图像的分辨率非常高。此外，针对360°视频，为避免观众产生运动病，帧率也需要保持较高[1]。因此，360°视频/图像在存储和传输方面面临巨大的压力。</p>
<p><strong>为了缓解存储和传输压力，压缩技术迫切需要节省360°视频/图像的比特率</strong>。在过去的几十年里，许多针对传统2D视频/图像的压缩标准由国际电信联盟（ITU）、联合图像专家组（JPEG）、动态图像专家组（MPEG）等组织制定。尽管360°图像和视频序列通过从球面投影到二维平面来存储、处理和传输[1]，但由于其球面特性，这些2D标准并不适用于360°视频/图像。因此，诸如MPEG-I[2]和JPEG 360[3]等项目被启动，以提高360°视频/图像的压缩效率，并且在360°视频/图像压缩方面付出了大量努力[2]。<strong>为了衡量压缩性能，需要进行视觉质量评估</strong>（<strong>VQA</strong>）<strong>以评估压缩引起的质量下降</strong>。然而，由于球面特性和球面到平面投影的存在，用于2D视频/图像的主观VQA推荐[4]–[6]和客观VQA方法[7]并不适用于360°视频/图像。在这种情况下，已经有一些研究工作在360°视频/图像上进行了VQA，从有效收集主观质量数据[8]，[9]和建模视觉质量[1]等方面进行了探讨。此外，通过HMD观看360°视频/图像的独特机制产生了两个事实：（1）在视口中的质量下降在360°视频/图像中更为显著，因为观众集中在视口，而视口只是整个360°视频/图像的一小部分；（2）在360°视频/图像编码的比特中存在大量冗余，因为视口外的巨大区域对观众是不可见的。受这些事实的启发，考虑人类感知可能有助于360°视频/图像的VQA和压缩。因此，也有许多研究集中在360°视频/图像的视觉注意力建模，以预测人类感知[10]，甚至举行了重大挑战赛[11]，[12]。总之，<strong>评估在压缩发展中起到基准和监控的作用；感知可以被纳入评估和压缩中，以进一步提高这两个领域的性能</strong>。图1中显示了这三个方面之间的三角关系，这是360°视频/图像处理的本质。因此，本文将这三个方面一起进行了综述。需要注意的是，<strong>360°与2D视频/图像之间在人类视觉感知方面的最大区别在于视觉注意力</strong>。这是因为360°视频/图像的<strong>观看范围和观看模式与2D视频/图像完全不同</strong>。因此，现有的大多数关于360°视频/图像感知模型的研究都<strong>集中在360°视频/图像的视觉注意力建模上</strong>。因此，本文主要讨论360°视频/图像感知中的视觉注意力。</p>
<p><img src="https://vip.helloimg.com/i/2024/08/19/66c34586e1f2f.png" width="50%" /></p>
<p>在360°视频/图像系统中，有许多因素会影响用户的视觉体验质量，例如HMD、360°视频/图像的内容、受处理影响的视觉质量以及流媒体中的网络状况。在这些因素中，360°视频/图像的视觉质量是一个关键因素，已经出现了大量相关研究并取得了重要成果。因此，本文主要讨论360°视频/图像的VQA。</p>
<p>尽管近年来针对360°视频/图像处理的研究大量涌现，但据我们所知，缺乏一篇综述性文章对这些研究进行回顾、总结并展望未来方向。本文从<strong>视觉注意力建模、视觉质量评估（VQA）和压缩</strong>等方面对360°视频/图像处理的研究进行了综述，并揭示了这些方面之间的关系。在视觉注意力建模方面，我们回顾了相关的数据集和方法。在VQA方面，首先对360°视频/图像的主观VQA方法进行了综述，这些方法<strong>通常提供带有主观质量评分的数据集</strong>。随后，我们重点讨论了客观VQA方法，这些方法旨在与360°视频/图像的主观质量评分保持一致。在压缩方面，我们回顾了那些结合了360°视频/图像的球面特性或感知机制的压缩方法。最后，我们对本文进行了总结，并展望了360°视频/图像处理领域的未来研究趋势。</p>
<h2 id="VISUAL-ATTENTION-MODELLING"><a href="#VISUAL-ATTENTION-MODELLING" class="headerlink" title="VISUAL ATTENTION MODELLING"></a>VISUAL ATTENTION MODELLING</h2><p>与传统的2D视频/图像不同，360°视频/图像可以在360×180°的范围内被感知。人类可以通过佩戴在球体内的头部显示器（HMD）选择视口来关注360°视频/图像中的吸引人的内容，而眼动（EM）决定了在视口中哪个区域可以以高分辨率（即，中央凹）被捕获。特别地，<strong>头部运动（HM）指的是被试视口的位置，而眼动（EM）反映了视口中的兴趣区域（RoI）</strong>。因此，360°视频/图像与2D视频/图像感知模型之间的主要区别是视觉注意力机制。换句话说，预测360°视频/图像上的视觉注意力作为感知模型，需要预测头部运动和眼动。在本节中，我们回顾了360°视频/图像上视觉注意力建模的数据集和方法。请注意，立体360°视频/图像中的视觉注意力建模的工作还很少[13]，[14]。因此，本文主要回顾了单目360°视频/图像上视觉注意力建模的现有工作。</p>
<h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><p>为了建立360°视频/图像的视觉注意力数据集，可以在虚拟现实环境中收集头部运动（HM）和眼动（EM）数据（除了Wild-360 [15]），即，被试通过佩戴头戴式显示器（HMD）来观看360°内容。具体来说，可以通过软件开发工具包（SDK）捕获HMD的姿态数据。基于姿态数据，可以计算并记录被试的HM数据。此外，可以嵌入到HMD中的眼动追踪器可以用来追踪瞳孔和角膜反射，以捕获EM数据。</p>
<p>最近，出现了许多用于360°视频/图像视觉注意力建模的数据集，这些数据集包含了被试的HM数据甚至EM数据。表I总结了这些数据集。请注意，表I中列出的所有数据集都是公开的，并且可以在线下载。表I中的数据集使得在被试观看360°视频/图像时对人类注意力进行分析成为可能。此外，这些数据集也促进了以数据为驱动的人类注意力建模方法。以下是一些广泛使用的数据集的更详细讨论。</p>
<p><img src="https://vip.helloimg.com/i/2024/08/19/66c33c951d101.png" width="120%"/></p>
<p><strong>Abreu等人</strong>[16]是最早的360°图像注意力数据集之一，建立于2017年。它包含21张360°图像，包括室内和室外场景。所有图像的分辨率均为4096×2048像素。共有32名受试者参与观看360°图像。在实验中，使用Oculus Rift DK2的HMD收集受试者的头部运动（HM）数据。受试者被分为两组，每组16人。对于一组，观看360°图像10秒；对于另一组，观看20秒。在数据收集的测试会话之前，他们的实验中有一个培训会话，使受试者熟悉HMD和360°图像。然后，允许他们在测试会话中自由观看图像，并捕获HMD的姿态数据。因此，为数据集获得了32名受试者的HM数据。</p>
<p><strong>Salient360数据集</strong>[10]，[23]包含360°图像[10]，[23]和视频[24]的头部运动（HM）和眼动（EM）数据。它们是流行的数据集，已被广泛用作许多最新视觉注意力模型[30]–[41]的训练集或基准。在[23]和[10]中，包括98张360°图像，分为5个类别：小型室内房间、宏伟的大厅、自然景观、城市景观和人物。其中，目前发布了60张。分辨率范围从5376×2688像素到18332×9166像素。然后，要求63名受试者通过HMD观看360°图像25秒，每个受试者自由观看60张图像的子集。因此，每张图像由40-42名受试者观看。在360°视频的Salient360数据集[24]中，包括19个视频序列，分辨率为3840×1920像素，按3组标签分类。每个序列持续20秒。共有57名受试者在实验中自由观看所有序列。值得一提的是，当受试者观看360°视频/图像时，他们坐在旋转椅上。对于这两个数据集，使用SMI的HMD嵌入式眼动追踪器，因此不仅收集了受试者的HM数据，还收集了EM数据。</p>
<p><strong>VR-EyeTracking</strong>[28]是一个大规模的360°视频数据集，包含受试者的头部运动（HM）和眼动（EM）数据。总共包括208个视频序列，内容多样，包括室内场景、户外活动、音乐会、体育比赛、纪录片、短片等。对于每个序列，分辨率至少为4K，持续时间从20到60秒不等。HM和EM数据是通过HTC Vive的HMD和aGlass的眼动追踪器捕获的。在实验中，招募了45名受试者观看视频序列。序列被分为6组，受试者每次自由观看一组。在两组之间的间隔中实施了眼动追踪器的重新校准。每个序列至少由31名受试者观看。最后，建立了VR-EyeTracking数据集。</p>
<p>表I中的数据集具有不同的特征，并适应不同的任务。例如，在数据驱动的注意力建模中，训练数据的数量和多样性很重要。因此，具有大规模和更多类别的数据集更适合这项任务，如VR-EyeTracking[28]和PVSHM[25]。然而，在研究受试者之间的一致性时，数据集中的受试者数量更重要，因此Bao等人[17]和Sitzmann等人[13]比其他数据集更适合这项任务。</p>
<p>根据现有的数据集，有几项研究从以下几个方面分析了360°视频/图像上人类注意力的情况。请注意，数据集分析可以进一步用于促进视觉注意力建模。</p>
<p>1) <strong>不同受试者之间的一致性</strong>：当观看360°视频/图像时，分析不同受试者之间视觉注意力的一致性至关重要。为此，以2D显著性图的形式建模人类注意力，这些图是将360°视频/图像的球体上的HM/EM注视点投影到2D平面上的热图。然后，不同受试者生成的显著性图的相似性表明了受试者之间视觉注意力的一致性。在[13]中，Sitzmann等人通过接收者操作特征（ROC）曲线比较了每个受试者与其余受试者之间的360°图像显著性图。ROC曲线快速收敛到最大速率1表明受试者之间高度一致。从数量上看，[13]中的分析发现70%的EM注视点落在20%最显著的区域中。对于360°视频，Xu等人[25]提出了计算两组受试者之间HM显著性图的皮尔逊线性相关系数（PLCC），每组包括一半的受试者。PLCC结果报告为0.83[25]，明显高于随机基线。总之，不同受试者对360°视频/图像的人类注意力高度一致。</p>
<p>2) <strong>赤道和中心偏好</strong>：当观看2D视频和图像时，人类更倾向于看视频/图像的中心。换句话说，2D视频/图像的EM数据存在中心偏好。同样，统计偏好也适用于360°视频/图像上的HM/EM注视点。对于360°图像，[13]和[31]发现受试者倾向于更频繁地观看赤道附近的区域，称为赤道偏好。赤道偏好也存在于360°视频的人类注意力中。此外，[25]和[24]的最新研究表明，受试者更频繁地观看360°视频的前部区域。因此，360°视频上的人类注意力倾向于赤道和前部区域，这与360°图像不同。前部偏好和赤道偏好可以作为360°视频/图像视觉注意力模型[25]，[30]–[36]，[40]，[41]中的先验知识，以提高其预测准确性。</p>
<p>3) <strong>内容对注意力的影响</strong>：[42]表明，除了统计偏好外，人类注意力与360°视频的内容高度相关。例如，<strong>360°视频中的显著对象有吸引人类注意力的潜力</strong>。这在[13]中得到了定量验证。[13]进一步发现，当显著对象的数量较少或位置接近时，它们会吸引更多的注意力。总之，360°视频/图像的内容对受试者的注意力有很大的影响。</p>
<p>4) <strong>HM和EM之间的关系</strong>：对于360°视频/图像，HM反映了受试者的视口位置，而EM指示受试者注视的地方。因此，<strong>HM和EM的分布可能不完全相同</strong>。Rai等人[43]发现，在360°图像的视口中，EM的分布呈现出类似火山的分布，显示了HM（视口中心）和EM之间的差异。他们还统计评估了从HM和EM生成的360°图像显著性图之间的差异。定量结果表明，<strong>HM的分布接近但仍然不同于EM</strong>。因此，一些研究开发了一个模型[31]，[34]，[36]来预测HM和EM显著性图，但更多的研究集中在HM预测[16]，[25]，[33]，[41]，[44]或EM预测[26]，[30]，[32]，[35]，[37]–[40]，或者他们分别提出了不同的模型来预测HM和EM显著性图。更多细节将在以下讨论。</p>
<h3 id="Attention-Modeling-Approaches"><a href="#Attention-Modeling-Approaches" class="headerlink" title="Attention Modeling Approaches"></a>Attention Modeling Approaches</h3><p>在本节中，我们回顾了360°视频/图像的注意力建模工作。它们主要指的是<strong>预测360°视频/图像的HM/EM显著性图</strong>，这些模型模拟了多个受试者的视口/兴趣区域（RoI）的分布。本文没有讨论其他一些注意力建模工作，例如，扫描路径预测[45]，[46]或单个受试者的HM/EM预测[25]，[28]，[44]，[47]。显著性预测工作大致可以分为<strong>启发式方法</strong>和<strong>数据驱动方法</strong>。</p>
<h4 id="Heuristic-Approaches"><a href="#Heuristic-Approaches" class="headerlink" title="Heuristic Approaches"></a>Heuristic Approaches</h4><p><img src="https://vip.helloimg.com/i/2024/08/19/66c3458ed2512.png" alt="2.png" title="2.png" /></p>
<blockquote>
<p>图2. 360°视频/图像启发式显著性方法的通用框架。该框架大致可分为3个步骤：预处理、特征提取和后处理。在预处理中，通过投影或视口提取获取360°视频/图像的2D内容。然后，提取与注意力相关的特征以生成显著性图，包括手工设计的特征和通过2D显著性方法提取的2D显著性特征。最后，应用几种后处理方法，如平滑和偏差，以生成最终的显著性图。</p>
</blockquote>
<p>启发式方法<strong>利用手工设计的特征对360°视频/图像上的注意力进行建模</strong>。图2显示了360°视频/图像上显著性方法的一般框架。启发式方法可以追溯到2008年。2008年，Bogdanova等人[48]，[49]提出了通过三个阶段预测360°图像上的显著性图：球体处理、特征提取和显著性图生成。首先，[49]在球体上开发了几种数据处理方法，包括滤波、高斯和Gabor金字塔、上采样和标准化。这些处理方法构成了球体视觉注意力模型的基础，甚至启发了最近关于球体卷积网络[50]的研究。其次，[49]遵循了2D图像的多尺度中心-环绕机制[51]来提取与注意力相关的特征，并将这些特征适应到360°图像的球体上。也就是说，提取了3种类型的7个特征：1个强度特征、2个色彩特征和4个局部方向特征。根据提取的特征，获得了7个球体显著性图，然后从球体显著性图中计算出强度、色度和方向的3个提示显著性图。最后，通过归一化后的3个提示显著性图融合生成显著性图。此后，Bogdanova等人提出了一种[52]360°视频的显著性预测方法。除了静态显著性图[49]外，他们进一步提出了计算360°视频的运动显著性图。具体来说，[49]首先提出了球体上的块匹配和运动金字塔计算方法，然后在运动幅度和相位上产生了球体运动显著性图。这些显著性图融合以获得每个360°视频帧的运动显著性图。最后，通过融合静态和运动显著性图获得动态显著性图。不幸的是，当时没有实际的HMD发布，因此无法收集受试者的HM和EM数据。结果，[48]，[49]，[52]中没有包括定量评估。</p>
<p>最近，HM和EM数据可以轻松收集，因此出现了许多360°视频/图像的显著性预测方法。由于2D图像和视频上的显著性预测方法已经高度发展[53]，<strong>直观地将2D显著性方法通过做一些修改适应到360°视频/图像上是自然而然的</strong>。然而，2D显著性方法在360°视频/图像上的适应<strong>可能会受到球体到平面投影引起的几何失真和边界伪影的影响</strong>。图3展示了几种常见的投影。从图3中可以看出，在投影平面上，视频/图像内容存在严重的几何失真，连续内容在边界上被打断。这些问题降低了直接应用于投影的360°视频/图像的2D显著性方法的性能[30]。因此，一些360°视频/图像显著性预测工作[16]，[30]，[31]，[54]努力解决这些问题。</p>
<p><img src="https://vip.helloimg.com/i/2024/08/19/66c3458cb176e.png" /></p>
<blockquote>
<p>图3. 360°视频/图像几种常见投影类型的示例，从中我们可以看到内容变形并引入了不连续的边界。在投影类型中，ERP是典型的圆柱投影；CMP是典型的多面体投影；TSP是具有不等面积面的多面体投影；CPP是伪圆柱投影，由于其等面积特性，通常用于质量评估。读者可参考[1]以获取更多关于360°视频/图像处理中投影的详细信息。</p>
</blockquote>
<p><strong>投影中的2D显著性特征</strong>：Abreu等人[16]提出了一种<strong>融合显著性图</strong>（FSM）方法，用于360°图像上的HM显著性预测，在该方法中，他们直接在等矩形投影（ERP）的球体到平面投影下应用了SALICON[55]（一种2D图像显著性预测方法）。 ……</p>
<p><strong>视口中的2D显著性特征</strong>：给定一个球面位置，可以获得与该位置对应的视口图像，使用球体到平面的正形投影[57]。对于360°视频/图像，一些其他工作[31]，[32]在<strong>视口图像上使用2D显著性预测方法</strong>，而不是投影的2D图像。优点是提取的360°视频/图像的视口图像几乎没有几何失真。然而，难点是如何将不同视口的显著性图整合在一起，以生成最终的球面显著性图。 ……</p>
<h4 id="Data-Driven-Approaches"><a href="#Data-Driven-Approaches" class="headerlink" title="Data-Driven Approaches"></a>Data-Driven Approaches</h4><p>360°视频/图像的视觉注意力模型也可以<strong>从训练数据中学习</strong>，得益于现有的数据集。随着数据集的建立，已经提出了几种显著性预测方法，用于预测360°图像[36, 39]，[44]或360°视频[15]，[25]，[26]，[40]，[41]的显著性图。</p>
<p><strong>表示学习</strong>：对于360°图像，Ling等人提出了基于颜色字典的稀疏表示（CDSR）方法[36]，用于HM和EM显著性预测。首先，在MIT1003[62]的2D图像上训练一个过度完备的颜色字典。在测试阶段，输入的360°图像首先被划分为子图像。<br>……</p>
<p><strong>360°图像的DNN</strong>：考虑到EM反映了受试者在视口内的注意力，Luz等人提出了一种显著性检测模型（SDM）方法[32]，用于在360°图像上建模EM，其中在对应于所有像素的球面位置上提取视口图像。然后，作者在视口图像上应用了预训练的多级网络（ML-Net）[67]，获得视口显著性图。视口显著性图通过赤道偏好加权整合在一起，得到360°图像的最终EM显著性图。<br>……</p>
<p><strong>360°视频的DNN</strong>：对于360°视频，Nguyen等人[44]在他们的PanoSalNet方法[44]中应用了2D图像显著性预测方法（即，SalNet），以预测每一帧的HM显著性图。然而，PanoSalNet模型在显著性预测中没有考虑时间特征。PanoSalNet模型在Corbillon等人[19]和Wu等人[21]的360°视频数据集上进行了微调，以便PanoSalNet方法可以用于360°视频显著性预测。与[44]相比，其他先进方法[15]，[25]，[26]，[41]在HM/EM显著性预测中考虑了360°视频的时间特征。<br>……</p>
<p><strong>强化学习</strong>：Xu等人[25]提出了一种360°视频的HM显著性预测方法，该方法利用深度强化学习（DRL），而不是传统工作中的监督学习。通过提出的基于DRL的HM预测（DHP）方法，一个智能体在对360°视频的HM行为的累积奖励上进行训练，以便智能体可以模仿一个受试者的长期HM行为。<br>……</p>
<h4 id="Summary-and-Outlook"><a href="#Summary-and-Outlook" class="headerlink" title="Summary and Outlook"></a>Summary and Outlook</h4><p>在视觉注意力建模方面，我们概述了几个包含注意力数据的公共360°视频/图像数据集。基于这些数据集，分析了人类对360°视频/图像的注意力。然后，我们回顾了360°视频/图像的显著性预测方法，包括启发式和数据驱动方法。对于启发式方法，通过显式提取手工设计的特征保证了可解释性。相反，数据驱动方法，特别是基于DNN的方法，自动提取特征进行显著性预测，具有相当的性能。自动特征提取充分利用了训练数据，但也带来了<strong>过拟合问题</strong>。过拟合问题可以从算法和数据两个方面解决，例如，引入先验知识、使用更大的训练集和数据增强。</p>
<p>然而，与包含多达4000张图像或1000个视频序列的2D视频/图像数据集[64]相比，<strong>360°视频/图像注意力数据集的规模相当小</strong>，这可能严重限制了数据驱动方法的上限。在当前阶段，360°视频/图像上的视觉注意力研究仍然缺乏足够的数据和深入分析，这是发展视觉注意力建模的前提。因此，迫切需要一些大规模的360°视频/图像数据集来进行注意力建模。值得注意的是，大多数方法集中在采用2D显著性预测方法或提取在2D显著性预测中已经证明有用的有用特征上，以便利用已经深入研究的2D视频/图像的视觉注意力机制。然而，也出现了一些方法[25]，[26]<strong>为360°视频/图像开发了全新的机制</strong>。鉴于未来360°视频/图像的更多和更大的可用数据集，可以为360°视频/图像做出更详细的视觉注意力机制发现。因此，360°视频/图像的显著性预测方法可以进一步发展，性能不断提高。</p>
<p>除了视觉注意力外，360°视频/图像中<strong>还有人类视觉感知的其他方面，特别是立体360°视频/图像的双眼视觉</strong>，这与2D视频/图像不同。例如，通过HMD显示的360°立体视频/图像具有其自身的人类视觉感知固有特征，这与普通立体3D显示的双眼视觉不同。然而，据我们所知，目前还没有分析360°视频/图像中这些视觉感知方面的工作。因此，除了注意力模型外，对360°视频/图像的其它感知方面的研究，例如<strong>360°立体图像/视频与普通立体视频/图像之间双眼视觉的差异</strong>，也是一个有前景的未来工作。反过来，它可能进一步有助于360°视频/图像的评估和压缩。</p>
<h2 id="VISUAL-QUALITY-ASSESSMENT"><a href="#VISUAL-QUALITY-ASSESSMENT" class="headerlink" title="VISUAL QUALITY ASSESSMENT"></a>VISUAL QUALITY ASSESSMENT</h2><h2 id="COMPRESSION"><a href="#COMPRESSION" class="headerlink" title="COMPRESSION"></a>COMPRESSION</h2><h2 id="CONCLUSION"><a href="#CONCLUSION" class="headerlink" title="CONCLUSION"></a>CONCLUSION</h2><p><img src="https://vip.helloimg.com/i/2024/08/19/66c3458910bd1.png" width="80%"/></p>
<p>最近，360°视频/图像非常流行，前景广阔，它提供了沉浸式体验，但同时也需要高保真度和低延迟。因此，对存储和传输提出了巨大挑战，这就需要对360°视频/图像进行专门的更高效的处理。在本文中，我们综述了360°视频/图像处理的最新研究工作，包括视觉注意力建模、VQA和压缩等方面。图4展示了本文的大纲。</p>
<p>事实上，360°视频/图像的感知、VQA和压缩并不是孤立存在的。例如，视觉注意力模型可能会促进360°视频/图像的VQA，因为人类是质量评估的最终终端；VQA是360°视频/图像压缩的优化目标。最近，多任务学习[174]已经成熟，它指的是同时学习多个任务。鉴于多任务学习，可以同时处理360°视频/图像的感知、VQA和压缩任务，因为这些任务不是孤立的。已经有开创性的工作[109]开发了一个多任务模型，用于预测360°视频的视口、显著性图和主观质量分数。未来360°视频/图像处理的长期目标应该包括更多的多任务工作，用于感知、VQA、压缩等。</p>
<p>作为单目360°视频/图像的衍生物，立体360°视频/图像甚至<strong>6自由度(6-DoF)视频/图像</strong>也在兴起。这些类型的视频/图像具有与单目360°视频/图像相同的球面特征，但也具有自己的固有特征。因此，立体360°或6-DoF视频/图像的感知、评估和压缩可能与单目360°视频/图像不同，显示出未来广阔的研究前景。</p>

    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.jpg" alt="AwayX 微信支付">
        <p>微信支付</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>AwayX
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://awayx.online/2024/08/19/State-of-the-Art%20in%20360%C2%B0%20Video_Image%20Processing%20-%20Perception,%20Assessment%20and%20Compression/" title="State-of-the-Art in 360° Video_Image Processing - Perception, Assessment and Compression">http://awayx.online/2024/08/19/State-of-the-Art in 360° Video_Image Processing - Perception, Assessment and Compression/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" rel="tag"><i class="fa fa-tag"></i> 论文笔记</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/08/19/Saliency%20Prediction%20on%20Omnidirectional%20Image%20With%20Generative%20Adversarial%20Imitation%20Learning/" rel="prev" title="Saliency Prediction on Omnidirectional Image With Generative Adversarial Imitation Learning">
      <i class="fa fa-chevron-left"></i> Saliency Prediction on Omnidirectional Image With Generative Adversarial Imitation Learning
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/08/20/Review%20on%20Panoramic%20Imaging%20and%20Its%20Applications%20%20in%20Scene%20Understanding/" rel="next" title="Review on Panoramic Imaging and Its Applications  in Scene Understanding">
      Review on Panoramic Imaging and Its Applications  in Scene Understanding <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC81OTUwMS8zNTk2Mw=="></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract"><span class="nav-number">1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#INTRODUCTION"><span class="nav-number">2.</span> <span class="nav-text">INTRODUCTION</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VISUAL-ATTENTION-MODELLING"><span class="nav-number">3.</span> <span class="nav-text">VISUAL ATTENTION MODELLING</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VISUAL-QUALITY-ASSESSMENT"><span class="nav-number">4.</span> <span class="nav-text">VISUAL QUALITY ASSESSMENT</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#COMPRESSION"><span class="nav-number">5.</span> <span class="nav-text">COMPRESSION</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CONCLUSION"><span class="nav-number">6.</span> <span class="nav-text">CONCLUSION</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="AwayX"
      src="/images/TheRightToCry.jpg">
  <p class="site-author-name" itemprop="name">AwayX</p>
  <div class="site-description" itemprop="description">嘿嘿</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">35</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/awaygithub" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;awaygithub" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:away2557103310@outlook.com" title="E-Mail → mailto:away2557103310@outlook.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://yoursite.com/" title="http:&#x2F;&#x2F;yoursite.com" rel="noopener" target="_blank">Title</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2024-02 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">AwayX</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.4' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script>

</body>
</html>
